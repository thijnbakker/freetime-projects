{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description \n",
    "\n",
    "A company has a lot of client data in  word, pdf, images etc. containing different types of graphs. They want to have this data stored in their database. \n",
    "\n",
    "They approached you with a dataset of extracted plots of different types, and want you to: \n",
    "\n",
    "__Classify images of plots into different classes: (2pts)__\n",
    "\n",
    "You are provided with a dataset.zip, containing images of different types of plots.  \n",
    "Tasks: \n",
    "\n",
    "a) Clean the dataset (remove any file which is corrupted, make sure images are in \n",
    "same format (.jpg or .png )) \n",
    "\n",
    "b) Build a classifier training code (pytorch or keras or classical ML  model anything is \n",
    "fine) \n",
    "\n",
    "c) Do the accuracy metrics analysis \n",
    "\n",
    "d) Save model \n",
    "\n",
    "e) Inference code testing your model on any image from the dataset \n",
    "\n",
    "\n",
    "__Deliverables:__\n",
    "1. Complete code or notebook \n",
    "2. Saved model file \n",
    "3. Documentation containing instructions to run your code and a requirements.txt (You can also make use of Markdown cells if you are using a notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all the needed imports\n",
    "from torchvision import transforms\n",
    "import keras.backend as K\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e) Inference code testing your model on any image from the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_mapping = {'bargraph': 0, 'flowchart': 1, 'linegraph': 2, 'piechart': 3, 'scatterplot': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = TP / (Positives+K.epsilon())\n",
    "        return recall\n",
    "    \n",
    "    def precision_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Pred_Positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = TP / (Pred_Positives+K.epsilon())\n",
    "        return precision\n",
    "    \n",
    "    precision, recall = precision_m(y_true, y_pred), recall_m(y_true, y_pred)\n",
    "    \n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model you trained in task5_training.ipynb\n",
    "image_size = 256\n",
    "model_file = f'simple_cnn_model_v4.h5'\n",
    "model = load_model(model_file, custom_objects={\"f1\": f1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed image shape: torch.Size([1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "# Load the image\n",
    "image_path = \"dataset_part1/bargraph/1.png\"\n",
    "image = Image.open(image_path).convert(\"RGB\") # Convert to RGB if not already\n",
    "\n",
    "# Define a transform to resize the image to 250x250\n",
    "resize_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Grayscale(num_output_channels=1),  # Convert to Grayscale\n",
    "])\n",
    "\n",
    "# Apply the transform to the image\n",
    "transformed_image = resize_transform(image)\n",
    "\n",
    "# Verify the transformation by checking the size of the transformed image\n",
    "print(f\"Transformed image shape: {transformed_image.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Prediction shape: (1, 5)\n",
      "Predicted class: 0\n",
      "Predicted label: bargraph\n"
     ]
    }
   ],
   "source": [
    "# Convert to NumPy and reshape for Keras (batch, height, width, channels)\n",
    "input_array = transformed_image.unsqueeze(0).numpy()  # Add batch dim: (1, 1, 256, 256)\n",
    "input_array = np.transpose(input_array, (0, 2, 3, 1))  # Reshape to (1, 256, 256, 1)\n",
    "\n",
    "# Predict with the model\n",
    "prediction = model.predict(input_array)\n",
    "\n",
    "# Display prediction shape or values depending on task\n",
    "print(f\"Prediction shape: {prediction.shape}\")\n",
    "\n",
    "# Get the predicted class\n",
    "predicted_class = prediction.argmax(axis=1)[0]\n",
    "\n",
    "# Print the predicted class\n",
    "print(f\"Predicted class: {predicted_class}\")\n",
    "\n",
    "# Map the predicted class index to the corresponding label\n",
    "predicted_label = list(index_mapping.keys())[list(index_mapping.values()).index(predicted_class)]\n",
    "print(f\"Predicted label: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets try one more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed image shape: torch.Size([1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "image_path = \"dataset_part1/linegraph/220px-Graph_%28PSF%29.png\"\n",
    "image = Image.open(image_path).convert(\"RGB\") # Convert to RGB if not already\n",
    "\n",
    "# Define a transform to resize the image to 250x250\n",
    "resize_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Grayscale(num_output_channels=1),  # Convert to Grayscale\n",
    "])\n",
    "\n",
    "# Apply the transform to the image\n",
    "transformed_image = resize_transform(image)\n",
    "\n",
    "# Verify the transformation by checking the size of the transformed image\n",
    "print(f\"Transformed image shape: {transformed_image.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "Prediction shape: (1, 5)\n",
      "Predicted class: 2\n",
      "Predicted label: linegraph\n"
     ]
    }
   ],
   "source": [
    "# Convert to NumPy and reshape for Keras (batch, height, width, channels)\n",
    "input_array = transformed_image.unsqueeze(0).numpy()  # Add batch dim: (1, 1, 256, 256)\n",
    "input_array = np.transpose(input_array, (0, 2, 3, 1))  # Reshape to (1, 256, 256, 1)\n",
    "\n",
    "# Predict with the model\n",
    "prediction = model.predict(input_array)\n",
    "\n",
    "# Display prediction shape or values depending on task\n",
    "print(f\"Prediction shape: {prediction.shape}\")\n",
    "\n",
    "# Get the predicted class\n",
    "predicted_class = prediction.argmax(axis=1)[0]\n",
    "\n",
    "# Print the predicted class\n",
    "print(f\"Predicted class: {predicted_class}\")\n",
    "\n",
    "# Map the predicted class index to the corresponding label\n",
    "predicted_label = list(index_mapping.keys())[list(index_mapping.values()).index(predicted_class)]\n",
    "print(f\"Predicted label: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatterplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed image shape: torch.Size([1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "image_path = \"dataset_part1/scatterplot/3207.png\"\n",
    "image = Image.open(image_path).convert(\"RGB\") # Convert to RGB if not already\n",
    "\n",
    "# Define a transform to resize the image to 250x250\n",
    "resize_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Grayscale(num_output_channels=1),  # Convert to Grayscale\n",
    "])\n",
    "\n",
    "# Apply the transform to the image\n",
    "transformed_image = resize_transform(image)\n",
    "\n",
    "# Verify the transformation by checking the size of the transformed image\n",
    "print(f\"Transformed image shape: {transformed_image.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "Prediction shape: (1, 5)\n",
      "Predicted class: 4\n",
      "Predicted label: scatterplot\n"
     ]
    }
   ],
   "source": [
    "# Convert to NumPy and reshape for Keras (batch, height, width, channels)\n",
    "input_array = transformed_image.unsqueeze(0).numpy()  # Add batch dim: (1, 1, 256, 256)\n",
    "input_array = np.transpose(input_array, (0, 2, 3, 1))  # Reshape to (1, 256, 256, 1)\n",
    "\n",
    "# Predict with the model\n",
    "prediction = model.predict(input_array)\n",
    "\n",
    "# Display prediction shape or values depending on task\n",
    "print(f\"Prediction shape: {prediction.shape}\")\n",
    "\n",
    "# Get the predicted class\n",
    "predicted_class = prediction.argmax(axis=1)[0]\n",
    "\n",
    "# Print the predicted class\n",
    "print(f\"Predicted class: {predicted_class}\")\n",
    "\n",
    "# Map the predicted class index to the corresponding label\n",
    "predicted_label = list(index_mapping.keys())[list(index_mapping.values()).index(predicted_class)]\n",
    "print(f\"Predicted label: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets grab 2 random images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed image shape: torch.Size([1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "image_path = \"test_images/piechart.png\"\n",
    "image = Image.open(image_path).convert(\"RGB\") # Convert to RGB if not already\n",
    "\n",
    "# Define a transform to resize the image to 250x250\n",
    "resize_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Grayscale(num_output_channels=1),  # Convert to Grayscale\n",
    "])\n",
    "\n",
    "# Apply the transform to the image\n",
    "transformed_image = resize_transform(image)\n",
    "\n",
    "# Verify the transformation by checking the size of the transformed image\n",
    "print(f\"Transformed image shape: {transformed_image.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "Prediction shape: (1, 5)\n",
      "Predicted class: 3\n",
      "Predicted label: piechart\n"
     ]
    }
   ],
   "source": [
    "# Convert to NumPy and reshape for Keras (batch, height, width, channels)\n",
    "input_array = transformed_image.unsqueeze(0).numpy()  # Add batch dim: (1, 1, 256, 256)\n",
    "input_array = np.transpose(input_array, (0, 2, 3, 1))  # Reshape to (1, 256, 256, 1)\n",
    "\n",
    "# Predict with the model\n",
    "prediction = model.predict(input_array)\n",
    "\n",
    "# Display prediction shape or values depending on task\n",
    "print(f\"Prediction shape: {prediction.shape}\")\n",
    "\n",
    "# Get the predicted class\n",
    "predicted_class = prediction.argmax(axis=1)[0]\n",
    "\n",
    "# Print the predicted class\n",
    "print(f\"Predicted class: {predicted_class}\")\n",
    "\n",
    "# Map the predicted class index to the corresponding label\n",
    "predicted_label = list(index_mapping.keys())[list(index_mapping.values()).index(predicted_class)]\n",
    "print(f\"Predicted label: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed image shape: torch.Size([1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "image_path = \"test_images/linegraph.png\"\n",
    "image = Image.open(image_path).convert(\"RGB\") # Convert to RGB if not already\n",
    "\n",
    "# Define a transform to resize the image to 250x250\n",
    "resize_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Grayscale(num_output_channels=1),  # Convert to Grayscale\n",
    "])\n",
    "\n",
    "# Apply the transform to the image\n",
    "transformed_image = resize_transform(image)\n",
    "\n",
    "# Verify the transformation by checking the size of the transformed image\n",
    "print(f\"Transformed image shape: {transformed_image.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "Prediction shape: (1, 5)\n",
      "Predicted class: 2\n",
      "Predicted label: linegraph\n"
     ]
    }
   ],
   "source": [
    "# Convert to NumPy and reshape for Keras (batch, height, width, channels)\n",
    "input_array = transformed_image.unsqueeze(0).numpy()  # Add batch dim: (1, 1, 256, 256)\n",
    "input_array = np.transpose(input_array, (0, 2, 3, 1))  # Reshape to (1, 256, 256, 1)\n",
    "\n",
    "# Predict with the model\n",
    "prediction = model.predict(input_array)\n",
    "\n",
    "# Display prediction shape or values depending on task\n",
    "print(f\"Prediction shape: {prediction.shape}\")\n",
    "\n",
    "# Get the predicted class\n",
    "predicted_class = prediction.argmax(axis=1)[0]\n",
    "\n",
    "# Print the predicted class\n",
    "print(f\"Predicted class: {predicted_class}\")\n",
    "\n",
    "# Map the predicted class index to the corresponding label\n",
    "predicted_label = list(index_mapping.keys())[list(index_mapping.values()).index(predicted_class)]\n",
    "print(f\"Predicted label: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The last model predicted everything correct!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed image shape: torch.Size([1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "image_path = \"test_images/banaan_2.png\"\n",
    "image = Image.open(image_path).convert(\"RGB\") # Convert to RGB if not already\n",
    "\n",
    "# Define a transform to resize the image to 250x250\n",
    "resize_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Grayscale(num_output_channels=1),  # Convert to Grayscale\n",
    "])\n",
    "\n",
    "# Apply the transform to the image\n",
    "transformed_image = resize_transform(image)\n",
    "\n",
    "# Verify the transformation by checking the size of the transformed image\n",
    "print(f\"Transformed image shape: {transformed_image.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "Prediction shape: (1, 5)\n",
      "Predicted class: 0\n",
      "Predicted label: bargraph\n"
     ]
    }
   ],
   "source": [
    "# Convert to NumPy and reshape for Keras (batch, height, width, channels)\n",
    "input_array = transformed_image.unsqueeze(0).numpy()  # Add batch dim: (1, 1, 256, 256)\n",
    "input_array = np.transpose(input_array, (0, 2, 3, 1))  # Reshape to (1, 256, 256, 1)\n",
    "\n",
    "# Predict with the model\n",
    "prediction = model.predict(input_array)\n",
    "\n",
    "# Display prediction shape or values depending on task\n",
    "print(f\"Prediction shape: {prediction.shape}\")\n",
    "\n",
    "# Get the predicted class\n",
    "predicted_class = prediction.argmax(axis=1)[0]\n",
    "\n",
    "# Print the predicted class\n",
    "print(f\"Predicted class: {predicted_class}\")\n",
    "\n",
    "# Map the predicted class index to the corresponding label\n",
    "predicted_label = list(index_mapping.keys())[list(index_mapping.values()).index(predicted_class)]\n",
    "print(f\"Predicted label: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed image shape: torch.Size([1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "image_path = \"test_images/lastig.png\"\n",
    "image = Image.open(image_path).convert(\"RGB\") # Convert to RGB if not already\n",
    "\n",
    "# Define a transform to resize the image to 250x250\n",
    "resize_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Grayscale(num_output_channels=1),  # Convert to Grayscale\n",
    "])\n",
    "\n",
    "# Apply the transform to the image\n",
    "transformed_image = resize_transform(image)\n",
    "\n",
    "# Verify the transformation by checking the size of the transformed image\n",
    "print(f\"Transformed image shape: {transformed_image.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n",
      "Prediction shape: (1, 5)\n",
      "Predicted class: 4\n",
      "Predicted label: scatterplot\n"
     ]
    }
   ],
   "source": [
    "# Convert to NumPy and reshape for Keras (batch, height, width, channels)\n",
    "input_array = transformed_image.unsqueeze(0).numpy()  # Add batch dim: (1, 1, 256, 256)\n",
    "input_array = np.transpose(input_array, (0, 2, 3, 1))  # Reshape to (1, 256, 256, 1)\n",
    "\n",
    "# Predict with the model\n",
    "prediction = model.predict(input_array)\n",
    "\n",
    "# Display prediction shape or values depending on task\n",
    "print(f\"Prediction shape: {prediction.shape}\")\n",
    "\n",
    "# Get the predicted class\n",
    "predicted_class = prediction.argmax(axis=1)[0]\n",
    "\n",
    "# Print the predicted class\n",
    "print(f\"Predicted class: {predicted_class}\")\n",
    "\n",
    "# Map the predicted class index to the corresponding label\n",
    "predicted_label = list(index_mapping.keys())[list(index_mapping.values()).index(predicted_class)]\n",
    "print(f\"Predicted label: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "y2_block_B",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
