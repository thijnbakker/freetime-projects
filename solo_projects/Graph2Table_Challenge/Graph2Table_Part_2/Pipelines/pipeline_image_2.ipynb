{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Full Pipeline of Image 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At this pipeline we will use the code from both task a and b\n",
    "\n",
    "__Tasks:__\n",
    "- a) Extract and print  ‘title of graph’ and make bounding boxes around the texts detected in the images and save the resultant images with Bounding boxes.Save images as ’ {image_name}_bboxes.png’ \n",
    "- b) Make use of computer vision skills, get individual bars and their values (Hint : contour detection, edge detection etc). Write the individual results into ‘{image_name}.csv’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import os\n",
    "import pytesseract\n",
    "import csv\n",
    "import pandas as pd\n",
    "import easyocr\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install easyocr\n",
    "# %pip install pytesseract\n",
    "# %pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Bar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and adjust the image\n",
    "image_path = os.path.join('dataset_part2', 'image_2.png')\n",
    "image = cv2.imread(image_path)\n",
    "output = image.copy()\n",
    "\n",
    "# Convert to HSV to isolate colored bars better\n",
    "hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Define a mask to isolate all strong color regions (ignoring yellow bg)\n",
    "# We'll keep saturation and value high to exclude light yellow\n",
    "lower = np.array([0, 100, 100])\n",
    "upper = np.array([179, 255, 255])\n",
    "mask = cv2.inRange(hsv, lower, upper)\n",
    "\n",
    "# Morph to remove small gaps/noise\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "# Find contours\n",
    "contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "bars = []\n",
    "for cnt in contours:\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "    if h > 50 and w > 20 and y > 50:  # basic bar-like filtering\n",
    "        bars.append((x, y, w, h))\n",
    "        cv2.line(output, (x, y + h), (x + w, y + h), (0, 255, 255), 2)\n",
    "\n",
    "\n",
    "# Highlight the largest bar\n",
    "if bars:\n",
    "    largest = max(bars, key=lambda b: b[2] * b[3])\n",
    "    # Crop the image to the size of the largest bar\n",
    "    x, y, w, h = largest  # Coordinates of the largest bar\n",
    "    cropped_image = output[y:y + h, x:x + w]\n",
    "    \n",
    "    # Save crop info for later use\n",
    "    crop_info = {\n",
    "    \"x\": x,\n",
    "    \"y\": y,\n",
    "    \"w\": w,\n",
    "    \"h\": h\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will use the cropped image to detect the 4 bars and get the bboxes of them and then save those values for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use k-means clustering to segment the image by color and isolate the bars more reliably\n",
    "Z = cropped_image.reshape((-1, 3))\n",
    "Z = np.float32(Z)\n",
    "\n",
    "# Define criteria, number of clusters(K) and apply kmeans()\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "K = 4  # number of color clusters\n",
    "_, labels, centers = cv2.kmeans(Z, K, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "# Convert back to uint8 and reshape to original image\n",
    "centers = np.uint8(centers)\n",
    "segmented_data = centers[labels.flatten()]\n",
    "segmented_image = segmented_data.reshape((cropped_image.shape))\n",
    "\n",
    "# Convert to grayscale and threshold to isolate the bars\n",
    "gray_segmented = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
    "_, thresh_segmented = cv2.threshold(gray_segmented, 200, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Find contours again\n",
    "contours_final, _ = cv2.findContours(thresh_segmented, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Draw only valid bar-like bounding boxes\n",
    "final_boxed_image = cropped_image.copy()\n",
    "detected_bars = []\n",
    "for cnt in contours_final:\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "    aspect_ratio = h / float(w)\n",
    "    if w > 10 and h > 100 and aspect_ratio > 1.5:\n",
    "        detected_bars.append((x, y, w, h))\n",
    "        cv2.rectangle(final_boxed_image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "# Convert for display\n",
    "final_boxed_rgb = cv2.cvtColor(final_boxed_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Now use the crop info to calculate the correct coordinates relative to the original image\n",
    "bars_in_original_image = []\n",
    "for (x, y, w, h) in detected_bars:\n",
    "    original_x = crop_info['x'] + x\n",
    "    original_y = crop_info['y'] + y\n",
    "    bars_in_original_image.append((original_x, original_y, w, h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now check all the detected bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude the biggest detected bar\n",
    "detected_bars_data = []\n",
    "max_area = max(bars_in_original_image, key=lambda bar: bar[2] * bar[3])  # Find the bar with the largest area\n",
    "\n",
    "for (x, y, w, h) in bars_in_original_image:  # Exclude the largest bar\n",
    "    detected_bars_data.append({\n",
    "        'x': x,\n",
    "        'y': y,\n",
    "        'width': w,\n",
    "        'height': h\n",
    "    })\n",
    "\n",
    "# Sort detected bars data by x-axis\n",
    "detected_bars_data_sorted = sorted(detected_bars_data, key=lambda bar: bar['x'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract all the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected first bar value: 8.0\n",
      "Calculated bar values: [8.0, 17.9, 10.0, 14.0]\n"
     ]
    }
   ],
   "source": [
    "# Draw a horizontal line on top of the first detected bar\n",
    "first_bar = detected_bars_data_sorted[0]\n",
    "line_y = first_bar['y']  # y-coordinate of the top of the first bar\n",
    "\n",
    "# On this line detect the first value\n",
    "first_value = None\n",
    "min_distance = float('inf')\n",
    "\n",
    "# Read image\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Initialize EasyOCR\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "# Run OCR\n",
    "results = reader.readtext(image)\n",
    "\n",
    "for (bbox, text, confidence) in results:\n",
    "    if confidence > 0.5:  # You can tweak this\n",
    "        top_left = tuple(map(int, bbox[0]))\n",
    "        bottom_right = tuple(map(int, bbox[2]))\n",
    "\n",
    "        # Get the center Y of the text box\n",
    "        text_center_y = (top_left[1] + bottom_right[1]) // 2\n",
    "\n",
    "        # Check if this text is just above the bar (e.g., within 20 pixels)\n",
    "        distance = abs(text_center_y - line_y)\n",
    "        if text_center_y < line_y and distance < 30:  # text must be above the bar\n",
    "            try:\n",
    "                value = float(text)\n",
    "                if distance < min_distance:\n",
    "                    first_value = value\n",
    "                    min_distance = distance\n",
    "            except ValueError:\n",
    "                continue  # Not a number, skip\n",
    "\n",
    "\n",
    "\n",
    "if first_value is None:\n",
    "    print(\"Could not detect a numerical value above the first bar.\")\n",
    "else:\n",
    "    print(f\"Detected first bar value: {first_value}\")\n",
    "\n",
    "    # Calculate scale and values for all bars\n",
    "    highest_bar_height = max(detected_bars_data_sorted, key=lambda bar: bar['height'])['height']\n",
    "    first_bar_height = first_bar['height']\n",
    "    scale_factor = first_value / first_bar_height\n",
    "\n",
    "    bar_values = []\n",
    "    for bar in detected_bars_data_sorted:\n",
    "        value = round(bar['height'] * scale_factor, 1)\n",
    "        bar_values.append(value)\n",
    "\n",
    "    print(\"Calculated bar values:\", bar_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect the text under the bars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bar titles list: ['Reading', 'Playing', 'Baking', 'Washing hands']\n"
     ]
    }
   ],
   "source": [
    "# Ensure Tesseract is installed and added to PATH\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# Dictionary to store bar coordinates and detected text\n",
    "bar_text_mapping = {}\n",
    "\n",
    "for bar in detected_bars_data_sorted:\n",
    "    x, y, width, height = bar['x'], bar['y'], bar['width'], bar['height']\n",
    "    \n",
    "    # Define ROI below the bar (adjust the height as needed)\n",
    "    roi_y_start = y + height + 10  # Start 10 pixels below the bar\n",
    "    roi_y_end = roi_y_start + 50   # Define height of the ROI\n",
    "\n",
    "    # Add a margin to the left and right of the bar's bounding box\n",
    "    margin = 50 # Adjust margin as needed\n",
    "    roi_x_start = max(0, x - margin)  # Ensure it doesn't go out of bounds\n",
    "    roi_x_end = min(image.shape[1], x + width + margin)  # Ensure it doesn't go out of bounds\n",
    "\n",
    "    # Extract the ROI with the expanded width\n",
    "    roi = image[roi_y_start:roi_y_end, roi_x_start:roi_x_end]\n",
    "    \n",
    "    # Perform OCR on the ROI\n",
    "    detected_text = pytesseract.image_to_string(roi, config='--psm 6').strip()\n",
    "    \n",
    "    # Map the detected text to the bar\n",
    "    bar_text_mapping[(x, y, width, height)] = detected_text\n",
    "    \n",
    "# Print the mapping of bars to detected text\n",
    "bar_titles = []\n",
    "for bar, text in bar_text_mapping.items():\n",
    "    bar_titles.append(text)\n",
    "print(\"Bar titles list:\", bar_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we have all the data and now it is time to gather the x-axis title and the y-axis title. And of course the Title of the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The extracted title is: ['Activities at home']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to image\n",
    "image_path = 'dataset_part2/image_2.png'\n",
    "output_dir = 'output_bboxes'\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Initialize EasyOCR reader )\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "# Read the image\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Crop the image to exclude useless parts\n",
    "image = image[:-80, :] \n",
    "\n",
    "# OCR text detection\n",
    "results = reader.readtext(image)\n",
    "title_text = []\n",
    "topmost_y = float('inf')\n",
    "\n",
    "for (bbox, text, confidence) in results:\n",
    "    if confidence > 0.1:\n",
    "        top_left = tuple(map(int, bbox[0]))\n",
    "        bottom_right = tuple(map(int, bbox[2]))\n",
    "\n",
    "        cv2.rectangle(image, top_left, bottom_right, (0, 255, 0), 2)\n",
    "\n",
    "        y = top_left[1]\n",
    "        if y <= topmost_y + 10:\n",
    "            topmost_y = min(topmost_y, y)\n",
    "            title_text.append(text)\n",
    "\n",
    "print(f\"The extracted title is: {title_text}\")\n",
    "\n",
    "# Save output image\n",
    "output_path = os.path.join(output_dir, \"image_2_bboxes_easyocr.png\")\n",
    "cv2.imwrite(output_path, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The x-axis and y-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The x-axis text is: Type of activity\n"
     ]
    }
   ],
   "source": [
    "# Extract the x-axis text\n",
    "words = []\n",
    "for (bbox, text, confidence) in results:\n",
    "    if confidence > 0.1:\n",
    "        top_left = tuple(map(int, bbox[0]))\n",
    "        bottom_right = tuple(map(int, bbox[2]))\n",
    "\n",
    "        cv2.rectangle(image, top_left, bottom_right, (0, 255, 0), 2)\n",
    "\n",
    "        words.append(text)\n",
    "        \n",
    "# Extract the last bounding box\n",
    "x_axis_text = results[-1][1]  # Access the text directly from the last result\n",
    "print(f\"The x-axis text is: {x_axis_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The y-axis text is: Number of children\n"
     ]
    }
   ],
   "source": [
    "# Extract the y-axis text\n",
    "image_path = 'dataset_part2/image_2.png'\n",
    "\n",
    "# Initialize EasyOCR reader\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "# Read the image\n",
    "image = cv2.imread(image_path)\n",
    "# Rotate the image to get the y-axis text\n",
    "rotated_image = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)\n",
    "\n",
    "# OCR text detection on the rotated image\n",
    "results_rotated = reader.readtext(rotated_image)\n",
    "y_axis_text = []\n",
    "\n",
    "for (bbox, text, confidence) in results_rotated:\n",
    "    if confidence > 0.1:\n",
    "        top_left = tuple(map(int, bbox[0]))\n",
    "        bottom_right = tuple(map(int, bbox[2]))\n",
    "\n",
    "        cv2.rectangle(rotated_image, top_left, bottom_right, (0, 255, 0), 2)\n",
    "\n",
    "        y_axis_text.append(text)\n",
    "\n",
    "# Extract the first bounding box\n",
    "y_axis_text = results_rotated[0][1]  # Access the text directly from the first result\n",
    "print(f\"The y-axis text is: {y_axis_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'Activities at home.csv' created successfully.\n",
      "  Type of activity  Number of children\n",
      "0          Reading                 8.0\n",
      "1          Playing                17.9\n",
      "2           Baking                10.0\n",
      "3    Washing hands                14.0\n"
     ]
    }
   ],
   "source": [
    "# Define the output CSV file path\n",
    "output_csv_path = f\"{'_'.join(title_text)}.csv\"\n",
    "\n",
    "# Combine bar text and values into rows\n",
    "rows = [{x_axis_text: bar_text_mapping[(bar['x'], bar['y'], bar['width'], bar['height'])], y_axis_text: value} for bar, value in zip(detected_bars_data_sorted, bar_values)]\n",
    "\n",
    "# Write to CSV\n",
    "with open(output_csv_path, mode='w', newline='') as csv_file:\n",
    "    fieldnames = [x_axis_text, y_axis_text]\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    writer.writerows(rows)\n",
    "\n",
    "print(f\"CSV file '{output_csv_path}' created successfully.\")\n",
    "\n",
    "# Print final values in a df\n",
    "df = pd.DataFrame(rows)\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Block_C_9_10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
