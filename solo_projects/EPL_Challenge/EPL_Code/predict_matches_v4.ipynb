{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['match_result'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 139\u001b[0m\n\u001b[0;32m    135\u001b[0m df_train_filtered \u001b[38;5;241m=\u001b[39m df_train_numeric[df_test_columns]\n\u001b[0;32m    137\u001b[0m \u001b[38;5;66;03m# Now df_train_filtered will have only the columns that exist in both df_train and df_test\u001b[39;00m\n\u001b[1;32m--> 139\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdf_train_filtered\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmatch_result\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m y \u001b[38;5;241m=\u001b[39m df_train_filtered[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatch_result\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    142\u001b[0m X_train, X_val, y_train, y_val \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, stratify\u001b[38;5;241m=\u001b[39my)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\y2_block_B\\lib\\site-packages\\pandas\\core\\frame.py:5258\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5111\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5112\u001b[0m     labels: IndexLabel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5119\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5120\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5121\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5122\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5123\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5256\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5257\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5260\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5264\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5265\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5266\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\y2_block_B\\lib\\site-packages\\pandas\\core\\generic.py:4549\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4547\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4548\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4549\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4552\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\y2_block_B\\lib\\site-packages\\pandas\\core\\generic.py:4591\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4589\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4590\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4591\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4592\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4594\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4595\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\y2_block_B\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6699\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6699\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6700\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6701\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['match_result'] not found in axis\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load datasets\n",
    "df_train = pd.read_csv(\"EPL_assignment/epl_matches_train.csv\")\n",
    "df_test = pd.read_csv(\"EPL_assignment/epl_matches_test.csv\")\n",
    "df_teams = pd.read_csv(\"EPL_assignment/epl_teams.csv\")\n",
    "df_players = pd.read_csv(\"EPL_assignment/epl_players.csv\")\n",
    "df_shots = pd.read_csv(\"EPL_assignment/epl_potential_shots.csv\")\n",
    "df_goals = pd.read_csv(\"EPL_assignment/epl_goals.csv\")\n",
    "\n",
    "# Ensure no missing values\n",
    "df_train.dropna(inplace=True)\n",
    "df_test.dropna(inplace=True)\n",
    "df_teams.dropna(inplace=True)\n",
    "df_players.dropna(inplace=True)\n",
    "df_shots.dropna(inplace=True)\n",
    "df_goals.dropna(inplace=True)\n",
    "\n",
    "# Create target variable 'match_result'\n",
    "def get_match_result(home_goals, away_goals):\n",
    "    if home_goals > away_goals:\n",
    "        return \"Win\"\n",
    "    elif home_goals < away_goals:\n",
    "        return \"Lose\"\n",
    "    else:\n",
    "        return \"Draw\"\n",
    "\n",
    "df_train[\"match_result\"] = df_train.apply(lambda x: get_match_result(x[\"home_team_goal\"], x[\"away_team_goal\"]), axis=1)\n",
    "\n",
    "# Convert date columns to datetime format\n",
    "df_teams[\"date\"] = pd.to_datetime(df_teams[\"date\"])\n",
    "df_players[\"date\"] = pd.to_datetime(df_players[\"date\"])\n",
    "\n",
    "# -------------------------\n",
    "# Merge Team & Player Data\n",
    "# -------------------------\n",
    "df_train = df_train.merge(df_teams, left_on=\"home_team_id\", right_on=\"team_id\", suffixes=(\"\", \"_home\"))\n",
    "df_train = df_train.merge(df_teams, left_on=\"away_team_id\", right_on=\"team_id\", suffixes=(\"\", \"_away\"))\n",
    "df_test = df_test.merge(df_teams, left_on=\"home_team_id\", right_on=\"team_id\", suffixes=(\"\", \"_home\"))\n",
    "df_test = df_test.merge(df_teams, left_on=\"away_team_id\", right_on=\"team_id\", suffixes=(\"\", \"_away\"))\n",
    "\n",
    "# Drop redundant team_id columns\n",
    "df_train.drop(columns=[\"team_id\", \"team_id_away\"], inplace=True)\n",
    "df_test.drop(columns=[\"team_id\", \"team_id_away\"], inplace=True)\n",
    "\n",
    "# Merge Player Data - Compute Average Skill per Team\n",
    "player_stats = [\"dribbling\", \"finishing\", \"short_passing\", \"ball_control\", \"acceleration\", \"stamina\"]\n",
    "df_players_avg = df_players.groupby(\"player_id\")[player_stats].mean().reset_index()\n",
    "\n",
    "def get_team_avg(df, prefix):\n",
    "    player_columns = [f\"{prefix}_player_{i}\" for i in range(1, 12)]\n",
    "    team_avg = df[player_columns].apply(lambda x: df_players_avg[df_players_avg[\"player_id\"].isin(x)].mean(), axis=1)\n",
    "    return team_avg[player_stats]\n",
    "\n",
    "df_train[player_stats] = get_team_avg(df_train, \"home\")\n",
    "df_train[[f\"{stat}_away\" for stat in player_stats]] = get_team_avg(df_train, \"away\")\n",
    "df_test[player_stats] = get_team_avg(df_test, \"home\")\n",
    "df_test[[f\"{stat}_away\" for stat in player_stats]] = get_team_avg(df_test, \"away\")\n",
    "\n",
    "# Drop player ID columns\n",
    "df_train.drop(columns=[f\"home_player_{i}\" for i in range(1, 12)] + [f\"away_player_{i}\" for i in range(1, 12)], inplace=True)\n",
    "df_test.drop(columns=[f\"home_player_{i}\" for i in range(1, 12)] + [f\"away_player_{i}\" for i in range(1, 12)], inplace=True)\n",
    "\n",
    "# -------------------------\n",
    "# Merge Shots Data\n",
    "# -------------------------\n",
    "df_shots[\"shot_type\"] = df_shots[\"shot_type\"].fillna(\"other\")  # Fill missing shot types\n",
    "\n",
    "# Count total shots per team\n",
    "df_shots_agg = df_shots.groupby([\"match_id\", \"team_id\"])[\"shot_number\"].count().reset_index()\n",
    "df_shots_agg.rename(columns={\"shot_number\": \"total_shots\"}, inplace=True)\n",
    "\n",
    "# Pivot shot types into separate columns\n",
    "df_shots_types = df_shots.pivot_table(index=[\"match_id\", \"team_id\"], columns=\"shot_type\", aggfunc=\"size\", fill_value=0).reset_index()\n",
    "\n",
    "# Merge shots data into training and test sets\n",
    "df_train = df_train.merge(df_shots_agg, left_on=[\"match_id\", \"home_team_id\"], right_on=[\"match_id\", \"team_id\"], how=\"left\").rename(columns={\"total_shots\": \"total_shots_home\"})\n",
    "df_train = df_train.merge(df_shots_agg, left_on=[\"match_id\", \"away_team_id\"], right_on=[\"match_id\", \"team_id\"], how=\"left\").rename(columns={\"total_shots\": \"total_shots_away\"})\n",
    "\n",
    "df_test = df_test.merge(df_shots_agg, left_on=[\"match_id\", \"home_team_id\"], right_on=[\"match_id\", \"team_id\"], how=\"left\").rename(columns={\"total_shots\": \"total_shots_home\"})\n",
    "df_test = df_test.merge(df_shots_agg, left_on=[\"match_id\", \"away_team_id\"], right_on=[\"match_id\", \"team_id\"], how=\"left\").rename(columns={\"total_shots\": \"total_shots_away\"})\n",
    "\n",
    "# Merge shot types data\n",
    "df_train = df_train.merge(df_shots_types, left_on=[\"match_id\", \"home_team_id\"], right_on=[\"match_id\", \"team_id\"], how=\"left\")\n",
    "df_test = df_test.merge(df_shots_types, left_on=[\"match_id\", \"home_team_id\"], right_on=[\"match_id\", \"team_id\"], how=\"left\")\n",
    "\n",
    "# -------------------------\n",
    "# Merge Goals Data\n",
    "# -------------------------\n",
    "df_goals_agg = df_goals.groupby([\"match_id\", \"team_id\"])[\"goal_number\"].count().reset_index()\n",
    "df_goals_agg.rename(columns={\"goal_number\": \"total_goals\"}, inplace=True)\n",
    "df_goals_agg.rename(columns={\"team_id\": \"goal_team_id\"}, inplace=True)\n",
    "\n",
    "# Merge goals data into training and test sets, ensuring no duplication of team_id\n",
    "df_train = df_train.merge(df_goals_agg, left_on=[\"match_id\", \"home_team_id\"], right_on=[\"match_id\", \"goal_team_id\"], how=\"left\").rename(columns={\"total_goals\": \"total_goals_home\"})\n",
    "df_train = df_train.merge(df_goals_agg, left_on=[\"match_id\", \"away_team_id\"], right_on=[\"match_id\", \"goal_team_id\"], how=\"left\").rename(columns={\"total_goals\": \"total_goals_away\"})\n",
    "\n",
    "df_test = df_test.merge(df_goals_agg, left_on=[\"match_id\", \"home_team_id\"], right_on=[\"match_id\", \"goal_team_id\"], how=\"left\").rename(columns={\"total_goals\": \"total_goals_home\"})\n",
    "df_test = df_test.merge(df_goals_agg, left_on=[\"match_id\", \"away_team_id\"], right_on=[\"match_id\", \"goal_team_id\"], how=\"left\").rename(columns={\"total_goals\": \"total_goals_away\"})\n",
    "\n",
    "# -------------------------\n",
    "# Compute Shot Efficiency\n",
    "# -------------------------\n",
    "df_train[\"goal_efficiency_home\"] = df_train[\"total_goals_home\"] / df_train[\"total_shots_home\"]\n",
    "df_train[\"goal_efficiency_away\"] = df_train[\"total_goals_away\"] / df_train[\"total_shots_away\"]\n",
    "df_test[\"goal_efficiency_home\"] = df_test[\"total_goals_home\"] / df_test[\"total_shots_home\"]\n",
    "df_test[\"goal_efficiency_away\"] = df_test[\"total_goals_away\"] / df_test[\"total_shots_away\"]\n",
    "\n",
    "# Fill NaNs with 0\n",
    "df_train.fillna(0, inplace=True)\n",
    "df_test.fillna(0, inplace=True)\n",
    "\n",
    "# -------------------------\n",
    "# Train Model & Predict\n",
    "# -------------------------\n",
    "label_encoder = LabelEncoder()\n",
    "df_train[\"match_result\"] = label_encoder.fit_transform(df_train[\"match_result\"])\n",
    "\n",
    "# Select only numeric columns (int64, float64)\n",
    "df_train_numeric = df_train.select_dtypes(include=['number'])\n",
    "df_test_numeric = df_test.select_dtypes(include=['number'])\n",
    "\n",
    "# Now df_train_numeric and df_test_numeric contains only numeric columns\n",
    "\n",
    "# Get the columns from df_test\n",
    "df_test_columns = df_test_numeric.columns\n",
    "\n",
    "# Remove the 'match_result' column from the list of df_test columns\n",
    "df_test_columns = df_test_columns[df_test_columns != 'match_result']\n",
    "\n",
    "# Filter df_train to only include columns that are also in df_test\n",
    "df_train_filtered = df_train_numeric[df_test_columns]\n",
    "\n",
    "# Now df_train_filtered will have only the columns that exist in both df_train and df_test\n",
    "\n",
    "X = df_train_filtered.drop(columns=[\"match_result\"])\n",
    "y = df_train_filtered[\"match_result\"]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_test_pred = clf.predict(df_test_numeric)\n",
    "\n",
    "df_test_numeric[\"predicted_match_result\"] = label_encoder.inverse_transform(y_test_pred)\n",
    "df_test_numeric[[\"home_team_id\", \"away_team_id\", \"predicted_match_result\"]].to_csv(\"predicted_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_numeric"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "y2_block_B",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
